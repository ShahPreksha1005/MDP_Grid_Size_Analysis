{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13731ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e13761",
   "metadata": {},
   "source": [
    "# Matrix Operations\n",
    "You perform various matrix operations on a 5x5 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2320736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 5\n",
    "goal_state = (4, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497b3fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns of the matrix:\n",
      "Column 1: [ 1  6 11 16 21]\n",
      "Column 2: [ 2  7 12 17 22]\n",
      "Column 3: [ 3  8 13 18 23]\n",
      "Column 4: [ 4  9 14 19 24]\n",
      "Column 5: [ 5 10 15 20 25]\n"
     ]
    }
   ],
   "source": [
    "# Extract columns\n",
    "column_1 = matrix[:, 0]  # First column\n",
    "column_2 = matrix[:, 1]  # Second column\n",
    "column_3 = matrix[:, 2]  # Third column\n",
    "column_4 = matrix[:, 3]  # Fourth column\n",
    "column_5 = matrix[:, 4]  # Fifth column\n",
    "\n",
    "# Print the columns\n",
    "print(\"\\nColumns of the matrix:\")\n",
    "print(\"Column 1:\", column_1)\n",
    "print(\"Column 2:\", column_2)\n",
    "print(\"Column 3:\", column_3)\n",
    "print(\"Column 4:\", column_4)\n",
    "print(\"Column 5:\", column_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aecc6973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix after adding 5 to each element:\n",
      "[[ 6  7  8  9 10]\n",
      " [11 12 13 14 15]\n",
      " [16 17 18 19 20]\n",
      " [21 22 23 24 25]\n",
      " [26 27 28 29 30]]\n",
      "Matrix after multiplying each element by 2:\n",
      "[[ 2  4  6  8 10]\n",
      " [12 14 16 18 20]\n",
      " [22 24 26 28 30]\n",
      " [32 34 36 38 40]\n",
      " [42 44 46 48 50]]\n",
      "Transposed Matrix:\n",
      "[[ 1  6 11 16 21]\n",
      " [ 2  7 12 17 22]\n",
      " [ 3  8 13 18 23]\n",
      " [ 4  9 14 19 24]\n",
      " [ 5 10 15 20 25]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix addition\n",
    "matrix_add = matrix + 5\n",
    "print(\"Matrix after adding 5 to each element:\")\n",
    "print(matrix_add)\n",
    "\n",
    "# Matrix multiplication (element-wise)\n",
    "matrix_mult = matrix * 2\n",
    "print(\"Matrix after multiplying each element by 2:\")\n",
    "print(matrix_mult)\n",
    "\n",
    "# Matrix transpose\n",
    "matrix_transpose = matrix.T\n",
    "print(\"Transposed Matrix:\")\n",
    "print(matrix_transpose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac6c5d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix reshaped to 1x25:\n",
      "[[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      "  25]]\n",
      "Matrix reshaped to 25x1:\n",
      "[[ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]\n",
      " [12]\n",
      " [13]\n",
      " [14]\n",
      " [15]\n",
      " [16]\n",
      " [17]\n",
      " [18]\n",
      " [19]\n",
      " [20]\n",
      " [21]\n",
      " [22]\n",
      " [23]\n",
      " [24]\n",
      " [25]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the matrix to 1x25\n",
    "matrix_reshaped = matrix.reshape(1, 25)\n",
    "print(\"Matrix reshaped to 1x25:\")\n",
    "print(matrix_reshaped)\n",
    "\n",
    "# Reshape the matrix to 25x1\n",
    "matrix_reshaped_25x1 = matrix.reshape(25, 1)\n",
    "print(\"Matrix reshaped to 25x1:\")\n",
    "print(matrix_reshaped_25x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "812e9045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened matrix:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the matrix\n",
    "matrix_flattened = matrix.flatten()\n",
    "print(\"Flattened matrix:\")\n",
    "print(matrix_flattened)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb98f8",
   "metadata": {},
   "source": [
    "# Markov Decision Process (MDP) Simulation\n",
    "This section simulates an MDP, where the agent moves through a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b09d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define states as positions in the grid (5x5)\n",
    "states = [(i, j) for i in range(grid_size) for j in range(grid_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87935d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define actions\n",
    "actions = ['up', 'down', 'left', 'right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa6b45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the rewards for each state-action pair\n",
    "rewards = {}\n",
    "for state in states:\n",
    "    if state == goal_state:\n",
    "        rewards[state] = 10  # Reward for reaching the goal\n",
    "    else:\n",
    "        rewards[state] = -1  # Penalty for every move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15d12d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transition dynamics\n",
    "def next_state(state, action):\n",
    "    i, j = state\n",
    "    if action == 'up':\n",
    "        return (max(i-1, 0), j)  # Stay within bounds\n",
    "    elif action == 'down':\n",
    "        return (min(i+1, grid_size-1), j)  # Stay within bounds\n",
    "    elif action == 'left':\n",
    "        return (i, max(j-1, 0))  # Stay within bounds\n",
    "    elif action == 'right':\n",
    "        return (i, min(j+1, grid_size-1))  # Stay within bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bba0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transition probabilities (deterministic)\n",
    "def transition_probability(state, action, next_state_):\n",
    "    if next_state(state, action) == next_state_:\n",
    "        return 1.0  # Deterministic transition\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "322afea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MDP model\n",
    "class MDP:\n",
    "    def __init__(self, states, actions, rewards, goal_state):\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "        self.rewards = rewards\n",
    "        self.goal_state = goal_state\n",
    "        \n",
    "    def step(self, state, action):\n",
    "        # Get the next state\n",
    "        next_state_ = next_state(state, action)\n",
    "        \n",
    "        # Get the reward for the next state\n",
    "        reward = self.rewards[next_state_]\n",
    "         # Return next state, reward\n",
    "        return next_state_, reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b40e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an MDP instance\n",
    "mdp = MDP(states, actions, rewards, goal_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f25b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a policy (random for simplicity)\n",
    "def random_policy(state):\n",
    "    return np.random.choice(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d96cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the agent's journey through the grid\n",
    "def simulate_mdp(mdp, start_state, policy, max_steps=10):\n",
    "    state = start_state\n",
    "    total_reward = 0\n",
    "    print(f\"Starting state: {state}\")\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        if state == mdp.goal_state:\n",
    "            print(f\"Reached goal state {mdp.goal_state} at step {step}\")\n",
    "            break\n",
    "        \n",
    "        action = policy(state)\n",
    "        next_state_, reward = mdp.step(state, action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        print(f\"Step {step + 1}: State: {state}, Action: {action}, Next State: {next_state_}, Reward: {reward}\")\n",
    "        state = next_state_\n",
    "    \n",
    "    print(f\"Total reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f728d87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting state: (0, 0)\n",
      "Step 1: State: (0, 0), Action: left, Next State: (0, 0), Reward: -1\n",
      "Step 2: State: (0, 0), Action: up, Next State: (0, 0), Reward: -1\n",
      "Step 3: State: (0, 0), Action: left, Next State: (0, 0), Reward: -1\n",
      "Step 4: State: (0, 0), Action: right, Next State: (0, 1), Reward: -1\n",
      "Step 5: State: (0, 1), Action: up, Next State: (0, 1), Reward: -1\n",
      "Step 6: State: (0, 1), Action: down, Next State: (1, 1), Reward: -1\n",
      "Step 7: State: (1, 1), Action: right, Next State: (1, 2), Reward: -1\n",
      "Step 8: State: (1, 2), Action: right, Next State: (1, 3), Reward: -1\n",
      "Step 9: State: (1, 3), Action: right, Next State: (1, 4), Reward: -1\n",
      "Step 10: State: (1, 4), Action: right, Next State: (1, 4), Reward: -1\n",
      "Total reward: -10\n"
     ]
    }
   ],
   "source": [
    "# Start the simulation from the top-left corner (0, 0)\n",
    "simulate_mdp(mdp, start_state=(0, 0), policy=random_policy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a638fe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting state: (0, 0)\n",
      "Step 1: State: (0, 0), Action: up, Next State: (0, 0), Reward: -1\n",
      "Step 2: State: (0, 0), Action: down, Next State: (1, 0), Reward: -1\n",
      "Step 3: State: (1, 0), Action: right, Next State: (1, 1), Reward: -1\n",
      "Step 4: State: (1, 1), Action: right, Next State: (1, 2), Reward: -1\n",
      "Step 5: State: (1, 2), Action: down, Next State: (2, 2), Reward: -1\n",
      "Step 6: State: (2, 2), Action: left, Next State: (2, 1), Reward: -1\n",
      "Step 7: State: (2, 1), Action: left, Next State: (2, 0), Reward: -1\n",
      "Step 8: State: (2, 0), Action: down, Next State: (3, 0), Reward: -1\n",
      "Step 9: State: (3, 0), Action: left, Next State: (3, 0), Reward: -1\n",
      "Step 10: State: (3, 0), Action: left, Next State: (3, 0), Reward: -1\n",
      "Total reward: -10\n"
     ]
    }
   ],
   "source": [
    "simulate_mdp(mdp, start_state=(0, 0), policy=random_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c994393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting state: (0, 0)\n",
      "Step 1: State: (0, 0), Action: up, Next State: (0, 0), Reward: -1\n",
      "Step 2: State: (0, 0), Action: right, Next State: (0, 1), Reward: -1\n",
      "Step 3: State: (0, 1), Action: right, Next State: (0, 2), Reward: -1\n",
      "Step 4: State: (0, 2), Action: left, Next State: (0, 1), Reward: -1\n",
      "Step 5: State: (0, 1), Action: up, Next State: (0, 1), Reward: -1\n",
      "Step 6: State: (0, 1), Action: right, Next State: (0, 2), Reward: -1\n",
      "Step 7: State: (0, 2), Action: down, Next State: (1, 2), Reward: -1\n",
      "Step 8: State: (1, 2), Action: down, Next State: (2, 2), Reward: -1\n",
      "Step 9: State: (2, 2), Action: right, Next State: (2, 3), Reward: -1\n",
      "Step 10: State: (2, 3), Action: right, Next State: (2, 4), Reward: -1\n",
      "Total reward: -10\n"
     ]
    }
   ],
   "source": [
    "simulate_mdp(mdp, start_state=(0, 0), policy=random_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7559d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
